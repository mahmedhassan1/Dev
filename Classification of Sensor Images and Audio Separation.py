# -*- coding: utf-8 -*-
"""ML_Group_7_Ass2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k0GLOutrKZWx90V3eOqv5hLFhaFteB-l

### FNN
"""

import numpy as np
import tensorflow as tf
import seaborn as sns
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import time
import cv2  # For reading and resizing images
import os

from google.colab import drive
drive.mount('/content/drive')

# to dataset
dataset_path = '/content/drive/MyDrive/Assignment 2 Machine learning Nov 2024'

# Image parameters
# Adjust based on the image sizes
img_width, img_height = 256, 256
batch_size = 16

# Number of classes
num_classes = 7

# Training data generator with data augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,  # 80-20 split for training and validation
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.15,
    zoom_range=0.15,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Validation data generator (only rescaling)
validation_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

# Training generator
train_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical',
    subset='training',  # Set as training data
    shuffle=True
)

# Validation generator
validation_generator = validation_datagen.flow_from_directory(
    dataset_path,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation',  # Set as validation data
    shuffle=False
)

# Print class indices
print(train_generator.class_indices)

# Building the Neural Network
model = Sequential()
model.add(Flatten(input_shape=(256, 256, 3)))  # Input layer: flatten 64x64x3 images into 1D vector

# Hidden layers
model.add(Dense(128, activation='tanh'))  # First hidden layer with 128 neurons and tanh activation function
model.add(Dense(64, activation='tanh'))   # Second hidden layer with 64 neurons and tanh activation function

# Output layer
model.add(Dense(7, activation='softmax'))  # Output layer for 3 classes with softmax activation

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Number of epochs
epochs = 10

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,  # Number of batches per epoch
    epochs=epochs,  # Number of epochs to train the model
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size  # Number of validation batches per epoch
)

# Evaluate the model
loss, accuracy = model.evaluate(validation_generator)
print(f'Loss: {loss}, Accuracy: {accuracy}')

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Confusion Matrix
# Make predictions on the validation set
Y_pred = model.predict(validation_generator)
y_pred = np.argmax(Y_pred, axis=1)

# Get true labels
y_true = validation_generator.classes

# Compute confusion matrix
cm = confusion_matrix(y_true, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=validation_generator.class_indices.keys())

# Plot confusion matrix
disp.plot(cmap=plt.cm.Blues)
# Rotate x-tick labels
plt.xticks(rotation=45)
plt.show()

from graphviz import Digraph

# Create a directed graph
dot = Digraph(format="png")
dot.attr(rankdir="LR")  # Left-to-Right direction for compact layout
dot.attr(dpi="300")  # High resolution for better quality
dot.attr(nodesep="0.7", ranksep="0.7")  # Adjust spacing

# Add nodes
dot.node("Input", "Input\n256x256x3", shape="ellipse", style="filled", fillcolor="lightblue", penwidth="2")
dot.node("Flatten", "Flatten\n256x256x3 -> 1D", shape="ellipse", style="filled", fillcolor="lightyellow", penwidth="2")
dot.node("Dense1", "Dense\n128 neurons\nActivation: Tanh", shape="box", style="rounded, filled", fillcolor="lightgreen", penwidth="2")
dot.node("Dense2", "Dense\n64 neurons\nActivation: Tanh", shape="box", style="rounded, filled", fillcolor="lightgreen", penwidth="2")
dot.node("Output", "Output\n7 Classes\nActivation: Softmax", shape="ellipse", style="filled", fillcolor="lightpink", penwidth="2")

# Add edges
edges = [
    ("Input", "Flatten"),
    ("Flatten", "Dense1"),
    ("Dense1", "Dense2"),
    ("Dense2", "Output"),
]

for edge in edges:
    dot.edge(edge[0], edge[1], arrowsize="1.2", style="rounded", penwidth="2")

# Render the diagram
dot.render("fnn_model_diagram", view=True)

import matplotlib.pyplot as plt

# Data
categories = ['Training', 'Validation']
accuracies = [36.54, 34.04]

# Create bar chart
plt.bar(categories, accuracies, color=['blue', 'orange'])
plt.title('Training vs. Validation Accuracy')
plt.ylabel('Accuracy (%)')
plt.ylim(0, 100)

# Add values on top of bars
for i, v in enumerate(accuracies):
    plt.text(i, v + 1, f"{v:.2f}%", ha='center')

# Show plot
plt.show()





import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix

# Evaluate the model
loss, accuracy = model.evaluate(validation_generator)
print(f'Loss: {loss}, Accuracy: {accuracy}')

# Confusion Matrix
# Make predictions on the validation set
Y_pred = model.predict(validation_generator)
y_pred = np.argmax(Y_pred, axis=1)
y_true = validation_generator.classes

# confusion matrix
cm = confusion_matrix(y_true, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=validation_generator.class_indices.keys())
fig, ax = plt.subplots(figsize=(6, 6))
disp.plot(cmap=plt.cm.Blues, ax=ax)
plt.xticks(rotation=45)
plt.show()





"""### CNN - Convolutional Neural Network"""

import os
import cv2
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.utils import class_weight
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator


# Replaced Ariel with an available font
plt.rcParams["font.family"] = "DejaVu Sans"

# Directories for good, medium, and bad folders
directories = {
    'tin_good' : r'/content/drive/MyDrive/Assignment 2 Machine learning Nov 2024/tin_good',
    'tin_medium' : r'/content/drive/MyDrive/Assignment 2 Machine learning Nov 2024/tin_medium',
    'tin_bad' : r'/content/drive/MyDrive/Assignment 2 Machine learning Nov 2024/tin_bad',
    'titanium_good' : '/content/drive/MyDrive/Assignment 2 Machine learning Nov 2024/titanium_good',
    'titanium_bad' : '/content/drive/MyDrive/Assignment 2 Machine learning Nov 2024/titanium_bad',
    'zink_bad' : '/content/drive/MyDrive/Assignment 2 Machine learning Nov 2024/zink_bad',
    'zink_good' : '/content/drive/MyDrive/Assignment 2 Machine learning Nov 2024/zink_good'
}

# Resize dimensions
resize_dim = (128, 128)  # Resize to 128*128

def load_images_from_directory(directories, resize_dim):
    images = []
    labels = []
    for label, folder in directories.items():
        for filename in os.listdir(folder):
            file_path = os.path.join(folder, filename)
            image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale
            if image is not None:
                image_resized = cv2.resize(image, resize_dim)
                images.append(image_resized)
                labels.append(label)
    return np.array(images, dtype='float32'), np.array(labels)

# Load images and labels
X, y = load_images_from_directory(directories, resize_dim)

# Encode the labels
label_mapping = {'tin_good':0, 'tin_medium':1, 'tin_bad':2, 'titanium_good':3, 'titanium_bad':4, 'zink_bad':5, 'zink_good':6}
y_encoded = np.array([label_mapping[label] for label in y])

# Normalize pixel values
X = X / 255.0

# Reshape for the neural network
X = X.reshape(X.shape[0], resize_dim[0], resize_dim[1], 1)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=11, stratify=y_encoded)

# Create an ImageDataGenerator for augmentation
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Fit the generator to the training data
datagen.fit(X_train)

# Augment the training data to increase the number of images by 1.5 times
augment_size = int(0.5 * X_train.shape[0])
X_train_augmented = np.empty((0, resize_dim[0], resize_dim[1], 1))
y_train_augmented = np.empty(0, dtype=int)

for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=augment_size, shuffle=False):
    X_train_augmented = np.vstack((X_train_augmented, X_batch))
    y_train_augmented = np.hstack((y_train_augmented, y_batch))
    if X_train_augmented.shape[0] >= X_train.shape[0] + augment_size:
        break

X_train_augmented = np.vstack((X_train, X_train_augmented[:augment_size]))
y_train_augmented = np.hstack((y_train, y_train_augmented[:augment_size]))

# Calculate class weights
class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_augmented), y=y_train_augmented)
class_weights_dict = dict(enumerate(class_weights))

# Build the Convolutional Neural Network
model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(resize_dim[0], resize_dim[1], 1)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add(Dense(7, activation='softmax'))  # Using softmax for multi-class classification

# Compile the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train the model with class weights
history = model.fit(X_train_augmented, y_train_augmented, epochs=18, batch_size=32, validation_data=(X_test, y_test), class_weight=class_weights_dict)

# Evaluate the model
train_loss, train_accuracy = model.evaluate(X_train_augmented, y_train_augmented)
test_loss, test_accuracy = model.evaluate(X_test, y_test)

# Make predictions
y_train_pred = np.argmax(model.predict(X_train_augmented), axis=1)
y_test_pred = np.argmax(model.predict(X_test), axis=1)

# Evaluate performance
train_precision = precision_score(y_train_augmented, y_train_pred, average='weighted')
train_recall = recall_score(y_train_augmented, y_train_pred, average='weighted')
train_f1 = f1_score(y_train_augmented, y_train_pred, average='weighted')
train_conf_matrix = confusion_matrix(y_train_augmented, y_train_pred)

test_precision = precision_score(y_test, y_test_pred, average='weighted')
test_recall = recall_score(y_test, y_test_pred, average='weighted')
test_f1 = f1_score(y_test, y_test_pred, average='weighted')
test_conf_matrix = confusion_matrix(y_test, y_test_pred)

# Print the performance metrics
performance_metrics = pd.DataFrame({
    'Dataset': ['Training', 'Testing'],
    'Accuracy': [train_accuracy, test_accuracy],
    'Precision': [train_precision, test_precision],
    'Recall': [train_recall, test_recall],
    'F1 Score': [train_f1, test_f1]})

print(performance_metrics)

# Define class labels
class_labels = ['tin_good', 'tin_medium', 'tin_bad', 'titanium_good', 'titanium_bad', 'zink_bad', 'zink_good']



from graphviz import Digraph

# Create a directed graph
dot = Digraph(format="png")
dot.attr(rankdir="TB")  # Top to Bottom direction

# Add nodes
dot.node("Input", "Input\n128x128x1", shape="box")
dot.node("Conv1", "Conv2D\n32 filters", shape="box")
dot.node("Pool1", "MaxPooling\n2x2", shape="box")
dot.node("Conv2", "Conv2D\n64 filters", shape="box")
dot.node("Pool2", "MaxPooling\n2x2", shape="box")
dot.node("Conv3", "Conv2D\n128 filters", shape="box")
dot.node("Pool3", "MaxPooling\n2x2", shape="box")
dot.node("Flatten", "Flatten", shape="ellipse")
dot.node("Dense1", "Dense\n64 units", shape="box")
dot.node("Dropout", "Dropout\n50%", shape="ellipse")
dot.node("Output", "Output\n7 Classes", shape="box")

# Add edges as pairs of nodes
edges = [
    ("Input", "Conv1"),
    ("Conv1", "Pool1"),
    ("Pool1", "Conv2"),
    ("Conv2", "Pool2"),
    ("Pool2", "Conv3"),
    ("Conv3", "Pool3"),
    ("Pool3", "Flatten"),
    ("Flatten", "Dense1"),
    ("Dense1", "Dropout"),
    ("Dropout", "Output"),
]

for edge in edges:
    dot.edge(edge[0], edge[1])

# Render diagram
dot.render("cnn_model_diagram", view=True)

from graphviz import Digraph

# Create a directed graph
dot = Digraph(format="png")
dot.attr(rankdir="LR")  # Left to Right direction for a compact layout
dot.attr(dpi="300")  # High resolution for better quality

# Add nodes with compact positions
dot.node("Input", "Input\n128x128x1", shape="ellipse", style="filled", fillcolor="lightblue")
dot.node("Conv1", "Conv2D\n32 filters", shape="box", style="rounded, filled", fillcolor="lightyellow")
dot.node("Pool1", "MaxPooling\n2x2", shape="box", style="rounded, filled", fillcolor="lightyellow")
dot.node("Conv2", "Conv2D\n64 filters", shape="box", style="rounded, filled", fillcolor="lightyellow")
dot.node("Pool2", "MaxPooling\n2x2", shape="box", style="rounded, filled", fillcolor="lightyellow")
dot.node("Conv3", "Conv2D\n128 filters", shape="box", style="rounded, filled", fillcolor="lightyellow")
dot.node("Pool3", "MaxPooling\n2x2", shape="box", style="rounded, filled", fillcolor="lightyellow")
dot.node("Flatten", "Flatten", shape="ellipse", style="filled", fillcolor="lightblue")
dot.node("Dense1", "Dense\n64 units", shape="box", style="rounded, filled", fillcolor="lightgreen")
dot.node("Dropout", "Dropout\n50%", shape="ellipse", style="filled", fillcolor="lightblue")
dot.node("Output", "Output\n7 Classes", shape="ellipse", style="filled", fillcolor="lightpink")

# Add edges with curved style
edges = [
    ("Input", "Conv1"),
    ("Conv1", "Pool1"),
    ("Pool1", "Conv2"),
    ("Conv2", "Pool2"),
    ("Pool2", "Conv3"),
    ("Conv3", "Pool3"),
    ("Pool3", "Flatten"),
    ("Flatten", "Dense1"),
    ("Dense1", "Dropout"),
    ("Dropout", "Output"),
]

for edge in edges:
    dot.edge(edge[0], edge[1], arrowsize="0.8", style="rounded")

# Render the diagram
dot.render("cnn_model_compact", view=True)

from graphviz import Digraph

# Create a directed graph
dot = Digraph(format="png")
dot.attr(rankdir="LR")  # Left to Right direction
dot.attr(dpi="300")  # High resolution for better quality
dot.attr(nodesep="0.5", ranksep="0.7")  # Reduce spacing between nodes

# Add nodes
dot.node("Input", "Input\n128x128x1", shape="ellipse", style="filled", fillcolor="lightblue", penwidth="2")
dot.node("Conv1", "Conv2D\n32 filters", shape="box", style="rounded, filled", fillcolor="lightyellow", penwidth="2")
dot.node("Pool1", "MaxPooling\n2x2", shape="box", style="rounded, filled", fillcolor="lightyellow", penwidth="2")
dot.node("Conv2", "Conv2D\n64 filters", shape="box", style="rounded, filled", fillcolor="lightyellow", penwidth="2")
dot.node("Pool2", "MaxPooling\n2x2", shape="box", style="rounded, filled", fillcolor="lightyellow", penwidth="2")
dot.node("Conv3", "Conv2D\n128 filters", shape="box", style="rounded, filled", fillcolor="lightyellow", penwidth="2")
dot.node("Pool3", "MaxPooling\n2x2", shape="box", style="rounded, filled", fillcolor="lightyellow", penwidth="2")
dot.node("Flatten", "Flatten", shape="ellipse", style="filled", fillcolor="lightblue", penwidth="2")
dot.node("Dense1", "Dense\n64 units", shape="box", style="rounded, filled", fillcolor="lightgreen", penwidth="2")
dot.node("Dropout", "Dropout\n50%", shape="ellipse", style="filled", fillcolor="lightblue", penwidth="2")
dot.node("Output", "Output\n7 Classes", shape="ellipse", style="filled", fillcolor="lightpink", penwidth="2")

# Add edges with reduced length
edges = [
    ("Input", "Conv1"),
    ("Conv1", "Pool1"),
    ("Pool1", "Conv2"),
    ("Conv2", "Pool2"),
    ("Pool2", "Conv3"),
    ("Conv3", "Pool3"),
    ("Pool3", "Flatten"),
    ("Flatten", "Dense1"),
    ("Dense1", "Dropout"),
    ("Dropout", "Output"),
]

for edge in edges:
    dot.edge(edge[0], edge[1], arrowsize="1.2", style="rounded", penwidth="2")

# Render the diagram
dot.render("cnn_model_compact", view=True)





"""#### CNN Hyperparameter Tuned"""

import os
import cv2
import numpy as np
import pandas as pd
from sklearn.utils import class_weight
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.model_selection import ParameterGrid
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam, SGD, RMSprop

# Directories for good, medium, and bad folders
directories = {
    'tin_good' : r'/content/drive/MyDrive/Assignment 2 Machine learning Nov 2024-20241208T141622Z-001/Assignment 2 Machine learning Nov 2024/tin_good',
    'tin_medium' : r'/content/drive/MyDrive/Assignment 2 Machine learning Nov 2024-20241208T141622Z-001/Assignment 2 Machine learning Nov 2024/tin_medium',
    'tin_bad' : r'/content/drive/MyDrive/Assignment 2 Machine learning Nov 2024-20241208T141622Z-001/Assignment 2 Machine learning Nov 2024/tin_bad',
    'titanium_good' : '/content/drive/MyDrive/Assignment 2 Machine learning Nov 2024-20241208T141622Z-001/Assignment 2 Machine learning Nov 2024/titanium_good',
    'titanium_bad' : '/content/drive/MyDrive/Assignment 2 Machine learning Nov 2024-20241208T141622Z-001/Assignment 2 Machine learning Nov 2024/titanium_bad',
    'zink_bad' : '/content/drive/MyDrive/Assignment 2 Machine learning Nov 2024-20241208T141622Z-001/Assignment 2 Machine learning Nov 2024/Zink_Bad',
    'zink_good' : '/content/drive/MyDrive/Assignment 2 Machine learning Nov 2024-20241208T141622Z-001/Assignment 2 Machine learning Nov 2024/ZInk_Good'
}

# Resize dimensions
resize_dim = (128, 128)

# Load images from directory
def load_images_from_directory(directories, resize_dim):
    images = []
    labels = []
    for label, folder in directories.items():
        for filename in os.listdir(folder):
            file_path = os.path.join(folder, filename)
            image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale
            if image is not None:
                image_resized = cv2.resize(image, resize_dim)
                images.append(image_resized)
                labels.append(label)
    return np.array(images, dtype='float32'), np.array(labels)

# Load images and labels
X, y = load_images_from_directory(directories, resize_dim)

# Encode the labels
label_mapping = {'tin_good': 0, 'tin_medium': 1, 'tin_bad': 2, 'titanium_good': 3, 'titanium_bad': 4, 'zink_bad': 5, 'zink_good': 6}
y_encoded = np.array([label_mapping[label] for label in y])

# Normalize pixel values
X = X / 255.0

# Reshape for the neural network
X = X.reshape(X.shape[0], resize_dim[0], resize_dim[1], 1)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=11, stratify=y_encoded)

# Calculate class weights
class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
class_weights_dict = dict(enumerate(class_weights))

# Define hyperparameter grid
param_grid = {
    'filters': [64, 128],
    'kernel_size': [(3,3),(5,5)],
    'dense_units': [64, 128],
    'dropout_rate': [0.3,0.5],
    'optimizer': ['adam', 'sgd', 'rmsprop'],
    'batch_size': [16, 32]
}

# Create combinations of parameters
grid = ParameterGrid(param_grid)

# Track results
results = []

# Perform Grid Search
for params in grid:
    print(f"Testing parameters: {params}")

    # Augment data for this combination
    datagen = ImageDataGenerator(
        rotation_range=20,
        width_shift_range=0.2,
        height_shift_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest'
    )
    datagen.fit(X_train)

    augment_size = int(0.5 * X_train.shape[0])
    X_train_augmented = np.empty((0, resize_dim[0], resize_dim[1], 1))
    y_train_augmented = np.empty(0, dtype=int)

    for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=augment_size, shuffle=False):
        X_train_augmented = np.vstack((X_train_augmented, X_batch))
        y_train_augmented = np.hstack((y_train_augmented, y_batch))
        if X_train_augmented.shape[0] >= X_train.shape[0] + augment_size:
            break

    X_train_augmented = np.vstack((X_train, X_train_augmented[:augment_size]))
    y_train_augmented = np.hstack((y_train, y_train_augmented[:augment_size]))

    # Build the model
    model = Sequential()
    model.add(Conv2D(params['filters'], (5, 5), activation='relu', input_shape=(resize_dim[0], resize_dim[1], 1)))
    model.add(MaxPooling2D((2, 2)))
    model.add(Conv2D(params['filters'] * 2, (5, 5), activation='relu'))
    model.add(MaxPooling2D((2, 2)))
    model.add(Conv2D(params['filters'] * 4,(5, 5), activation='relu'))
    model.add(MaxPooling2D((2, 2)))
    model.add(Flatten())
    model.add(Dense(params['dense_units'], activation='relu'))
    model.add(Dropout(0.3))
    model.add(Dense(7, activation='softmax'))

    # Compile the model
    optimizer = Adam() if params['optimizer'] == 'adam' else SGD() if params['optimizer'] == 'sgd' else RMSprop()
    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    # Train the model
    history = model.fit(
        X_train_augmented, y_train_augmented,
        epochs=10,
        batch_size=params['batch_size'],
        validation_data=(X_test, y_test),
        class_weight=class_weights_dict,
        verbose=0
    )

    # Evaluate the model
    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)

    # Store results
    results.append({
        'filters': params['filters'],
        'dense_units': params['dense_units'],
        'optimizer': params['optimizer'],
        'batch_size': params['batch_size'],
        'test_accuracy': test_accuracy,
        'test_loss': test_loss
    })

# Convert results to DataFrame
results_df = pd.DataFrame(results)

# Find the best parameters
best_params = results_df.sort_values(by='test_accuracy', ascending=False).iloc[0]
print("Best Parameters:")
print(best_params)

from tensorflow.keras.utils import plot_model

# Save and visualize the model architecture
plot_model(model, to_file='cnn_architecture.png', show_shapes=True, show_layer_names=True)

# final confusion matrix
plt.figure(figsize=(6, 4))
sns.heatmap(pd.DataFrame(test_conf_matrix, index=class_labels, columns=class_labels), annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('Testing Data Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# Effects of epochs on accuracy
plt.figure(figsize=(6, 4))
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Test Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.ylim(0, 1)
plt.legend()
plt.title('Effect of Epochs on Accuracy')
plt.show()

# Effect of epochs on the loss function
plt.figure(figsize=(6, 4))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Test Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.ylim(0, max(max(history.history['loss']), max(history.history['val_loss'])) * 1.1)
plt.legend()
plt.title('Effect of Epochs on Loss Function')
plt.show()





"""### Generate csv files"""

# !pip install winsound

# Import necessary libraries
import os
import cv2
import numpy as np
import pandas as pd
from joblib import Parallel, delayed
import seaborn as sns
import matplotlib.pyplot as plt
# import winsound

# Function to apply filters and extract features
def extract_features(image_path):
    img = cv2.imread(image_path)
    if img is None:
        print(f"Error reading image: {image_path}")
        return None

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Resize image to speed up processing
    gray = cv2.resize(gray, (256, 256))

    features = {}

    # Calculate mean and standard deviation of grayscale pixel values
    features['gray_mean'] = np.mean(gray)
    features['gray_std'] = np.std(gray)

    # Combined mean of Gaussian Blur, Median Filter, and original gray
    gaussian_blur = cv2.GaussianBlur(gray, (5, 5), 3)
    median_blur = cv2.medianBlur(gray, 3)
    combined_blur_mean = np.mean([np.mean(gray), np.mean(gaussian_blur), np.mean(median_blur)])
    combined_blur_std = np.mean([np.std(gray), np.std(gaussian_blur), np.std(median_blur)])
    features['combined_blur_mean'] = combined_blur_mean
    features['combined_blur_std'] = combined_blur_std

    # Sobel Filter: Computes the gradient of the image intensity, useful for edge detection
    sobelx = cv2.Sobel(gray, cv2.CV_64F, 3, 1, ksize=7)
    sobely = cv2.Sobel(gray, cv2.CV_64F, 3, 1, ksize=7)
    sobel_mag = np.sqrt(sobelx**2 + sobely**2)
    combined_sobel = np.mean([np.mean(sobel_mag), np.std(sobel_mag)])
    features['combined_sobel'] = combined_sobel

    # Canny Edge Detection: Detects edges by looking for areas of rapid intensity change
    canny_edges = cv2.Canny(gray, 1, 3)
    combined_canny = np.mean([np.mean(canny_edges), np.std(canny_edges)])
    features['combined_canny'] = combined_canny

    return features

# Function to process images in a specified directory
def process_images(directory, label):
    data = []

    def process_file(filename):
        file_path = os.path.join(directory, filename)
        try:
            print(f"Processing {file_path}...")
            features = extract_features(file_path)
            if features:
                features['label'] = label
                return features
        except Exception as e:
            print(f"Error processing {file_path}: {e}")
            return None

    filenames = [f for f in os.listdir(directory) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
    print(f"Found {len(filenames)} images in {directory} for label '{label}'.")

    results = Parallel(n_jobs=-1)(delayed(process_file)(filename) for filename in filenames)

    data = [res for res in results if res is not None]

    return data

# Directories for good and bad folders
directories = {
    # 'bad':r'C:\Users\DCU\OneDrive\Documents\POST DOC16 04 24\C2C\Zn paper\Zn test-20240816T084743Z-001\Zn test\AI paper\Bad',
    # 'good': r'C:\Users\DCU\OneDrive\Documents\POST DOC16 04 24\C2C\Zn paper\Zn test-20240816T084743Z-001\Zn test\AI paper\good',
    'tin_good' : r'/content/drive/MyDrive/Assignment 2 Machine learning Nov 2024/tin_good',
    'tin_medium' : r'/content/drive/MyDrive/Assignment 2 Machine learning Nov 2024/tin_medium',
    'tin_bad' : r'/content/drive/MyDrive/Assignment 2 Machine learning Nov 2024/tin_bad',
    'titanium_good' : '/content/drive/MyDrive/Assignment 2 Machine learning Nov 2024/titanium_good',
    'titanium_bad' : '/content/drive/MyDrive/Assignment 2 Machine learning Nov 2024/titanium_bad',
    'zink_bad' : '/content/drive/MyDrive/Assignment 2 Machine learning Nov 2024/zink_bad',
    'zink_good' : '/content/drive/MyDrive/Assignment 2 Machine learning Nov 2024/zink_good'
}


# Process images for each directory
data = []
for label, directory in directories.items():
    data.extend(process_images(directory, label))

# Save to CSV
# output_csv = r'C:\Users\DCU\OneDrive\Documents\POST DOC16 04 24\C2C\Zn paper\Zn test-20240816T084743Z-001\Zn test\AI paper\Zn_file1.csv'
output_csv = r'/content/drive/MyDrive/assignment2_data.csv'
df = pd.DataFrame(data)
df.to_csv(output_csv, index=False)

# # Example output
# print("Processed data saved to CSV file:")
# print(output_csv)
# winsound.Beep(1000, 500)



"""### XGBoost & RandomForest classifier"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix
from sklearn.preprocessing import StandardScaler
import seaborn as sns
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.decomposition import PCA
from imblearn.over_sampling import SMOTE
# import winsound  # For playing a sound on Windows

# Load the dataset from a CSV file
df = pd.read_csv('/content/drive/MyDrive/Assignment 2 Machine learning Nov 2024/assignment2_data.csv')

# Change the names of the columns
df.columns = ['gray_mean', 'gray_std', 'combined_blur_mean', 'combined_blur_std', 'combined_sobel', 'combined_canny', 'label']

X = df.drop(['label'], axis=1)
y = df['label']

# Define label names
label_names = ['tin_good', 'tin_medium', 'tin_bad', 'titanium_good', 'titanium_bad', 'zink_bad', 'zink_good']

# Encode the labels
label_encoding = {'tin_good':0, 'tin_medium':1, 'tin_bad':2, 'titanium_good':3, 'titanium_bad':4, 'zink_bad':5, 'zink_good':6}
y = y.map(label_encoding)

# Split data for training and testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# Feature scaling (optional for XGBoost, as it handles scaling well)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""We created two functions:
*   evaluate_model: takes model and data, evaluate the models on both training and testing data by calculating metrics like accuracy, precision, recall and F1 score & visualize confusion matrices

*   get_evaluation_metrics: to compute evaluation metrics (accuracy, precision, recall, F1 score) for a model on training and testing datasets and returns them in a dictionary
"""

def evaluate_model(model, X_train, y_train, X_test, y_test, label_names, model_name='Model'):
    # Predictions
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    # Evaluation Metrics
    metrics = {
        'Train Accuracy': accuracy_score(y_train, y_train_pred),
        'Train Precision': precision_score(y_train, y_train_pred, average='macro'),
        'Train Recall': recall_score(y_train, y_train_pred, average='macro'),
        'Train F1 Score': f1_score(y_train, y_train_pred, average='macro'),
        'Test Accuracy': accuracy_score(y_test, y_test_pred),
        'Test Precision': precision_score(y_test, y_test_pred, average='macro'),
        'Test Recall': recall_score(y_test, y_test_pred, average='macro'),
        'Test F1 Score': f1_score(y_test, y_test_pred, average='macro')
    }

    # Print Metrics
    print(f'--- {model_name} Evaluation Metrics ---')
    for metric_name, value in metrics.items():
        print(f'{metric_name}: {value:.2f}')

    # Confusion Matrices
    for dataset, y_true, y_pred in [('Training', y_train, y_train_pred), ('Testing', y_test, y_test_pred)]:
        conf_matrix = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
                    xticklabels=label_names, yticklabels=label_names)
        plt.xlabel('Predicted', fontsize=12)
        plt.ylabel('Actual', fontsize=12)
        plt.title(f'{model_name} {dataset} Confusion Matrix', fontsize=16)
        plt.xticks(rotation=45, fontsize=10)
        plt.yticks(rotation=0, fontsize=10)
        plt.show()

def get_evaluation_metrics(model, X_train, y_train, X_test, y_test):
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    metrics = {
        'Train Accuracy': accuracy_score(y_train, y_train_pred),
        'Train Precision': precision_score(y_train, y_train_pred, average='macro'),
        'Train Recall': recall_score(y_train, y_train_pred, average='macro'),
        'Train F1 Score': f1_score(y_train, y_train_pred, average='macro'),
        'Test Accuracy': accuracy_score(y_test, y_test_pred),
        'Test Precision': precision_score(y_test, y_test_pred, average='macro'),
        'Test Recall': recall_score(y_test, y_test_pred, average='macro'),
        'Test F1 Score': f1_score(y_test, y_test_pred, average='macro')
    }

    return metrics

"""##### Best parameters for XGBoost Classifier"""

# parameter grid
param_grid = {
    'n_estimators': [10,20,30,40,50],
   'max_depth': [None, 10, 15, 20],
    'learning_rate': [0.01, 0.1, 0.2, 0.3],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0],
    'gamma': [0, 0.1, 0.2, 0.3]
}

# XGBoost Classifier
xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')

# get best params using GridSearchCV
xgb_grid_search = GridSearchCV(estimator=xgb_clf, param_grid=param_grid,
                           cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=11),
                           n_jobs=-1, verbose=2)

# grid search on training data
xgb_grid_search.fit(X_train, y_train)
best_xgb_model = xgb_grid_search.best_estimator_  # Retrieve the best estimator

# Print the best parameters
print(f'Best parameters: {xgb_grid_search.best_params_}')

"""##### Best parameters for Random Forest Classifier"""

# parameter grid
rf_param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False]
}

# Random Forest Classifier
rf_clf = RandomForestClassifier(random_state=42)

# Initialize GridSearchCV
rf_grid_search = GridSearchCV(
    estimator=rf_clf,
    param_grid=rf_param_grid,
    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),
    n_jobs=-1,
    verbose=2,
    scoring='accuracy'
)
rf_grid_search.fit(X_train, y_train)
best_rf_model = rf_grid_search.best_estimator_ # best estimator

# best parameters
print(f'Random Forest Best Parameters: {rf_grid_search.best_params_}')

# Call functions to evaluate XGBoost
evaluate_model(best_xgb_model, X_train, y_train, X_test, y_test, label_names, model_name='XGBoost')

# Call functions to evaluate the Random Forest model
evaluate_model(best_rf_model, X_train, y_train, X_test, y_test, label_names, model_name='Random Forest')

"""##### Models with PCA (Principal Component Analysis)



"""

# Initialize PCA - choose number of components or variance to retain
pca = PCA(n_components=0.95, random_state=42)  # Retain 95% variance
X_train_pca = pca.fit_transform(X_train) # Fit PCA on training data

# Transform test data
X_test_pca = pca.transform(X_test)
print(f'Original number of features: {X_train.shape[1]}')
print(f'Reduced number of features after PCA: {X_train_pca.shape[1]}')

# get best best_xgb_model
best_xgb_params = best_xgb_model.get_params()
best_xgb_pca_model = XGBClassifier(**best_xgb_params)


# Fit the model on PCA-transformed training data
best_xgb_pca_model.fit(X_train_pca, y_train)

# Evaluate the new XGBoost model trained on PCA-transformed data
evaluate_model(
    best_xgb_pca_model,
    X_train_pca,
    y_train,
    X_test_pca,
    y_test,
    label_names,
    model_name='XGBoost PCA'
)

# get best rf_model
best_rf_params = best_rf_model.get_params()
best_rf_pca_model = RandomForestClassifier(**best_rf_params)

# Fit the model on PCA-transformed training data
best_rf_pca_model.fit(X_train_pca, y_train)

# call function to evaluate
evaluate_model(best_rf_pca_model, X_train_pca, y_train, X_test_pca, y_test, label_names, model_name='Random Forest PCA')

# Plotting the cumulative explained variance
plt.figure(figsize=(8,6))
plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')
plt.xlabel('Number of Components')
plt.ylabel('Cumulative Explained Variance')
plt.title('Explained Variance by PCA Components')
plt.grid(True)
plt.show()

"""##### SMOTE: Class Imbalances"""

# Check class distribution
class_counts = y.value_counts()
print(class_counts)

# Visualize class distribution
sns.countplot(x=y)
plt.title('Class Distribution')
plt.xlabel('Class')
plt.ylabel('Count')
plt.show()

# Reverse the label encoding
reverse_label_mapping = {v: k for k, v in label_mapping.items()}
y_original = pd.Series([reverse_label_mapping[encoded_label] for encoded_label in y_encoded])

# Check class distribution with original labels
class_counts_original = y_original.value_counts()
print(class_counts_original)

# Visualize class distribution with original labels
sns.countplot(x=y_original, order=class_counts_original.index)
plt.title('Class Distribution')
plt.xlabel('Class')
plt.ylabel('Count')
plt.xticks(rotation=45)  # Rotate x-axis labels if needed
plt.show()

# Initialize SMOTE
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train) # SMOTE to training data

print('After SMOTE, the class distribution:')
print(pd.Series(y_train_smote).value_counts())

# We then used SMOTE on our best models
best_xgb_params = best_xgb_model.get_params()
best_xgb_smote_model = XGBClassifier(**best_xgb_params)


# Fit the XGBoost model on PCA-transformed training data & Evaluate
best_xgb_smote_model.fit(X_train_smote, y_train_smote)
evaluate_model(best_xgb_smote_model, X_train_smote, y_train_smote, X_test, y_test, label_names, model_name='XGBoost PCA')

# print(f'Random Forest with SMOTE Best Parameters: {rf_grid_search_smote.best_params_}')
best_rf_params = best_rf_model.get_params()
best_rf_smote_model = RandomForestClassifier(**best_rf_params)


# Fit the model on PCA-transformed training data & Evaluate
best_rf_smote_model.fit(X_train_smote, y_train_smote)
evaluate_model(best_rf_model, X_train_smote, y_train_smote, X_test, y_test, label_names, model_name='Random Forest SMOTE')


# Get metrics for all models
xgb_metrics = get_evaluation_metrics(best_xgb_model, X_train, y_train, X_test, y_test)
rf_metrics = get_evaluation_metrics(best_rf_model, X_train, y_train, X_test, y_test)
xgb_pca_metrics = get_evaluation_metrics(best_xgb_pca_model, X_train_pca, y_train, X_test_pca, y_test)
xgb_smote_metrics = get_evaluation_metrics(best_xgb_smote_model, X_train_smote, y_train_smote, X_test, y_test)
rf_pca_metrics = get_evaluation_metrics(best_rf_pca_model, X_train_pca, y_train, X_test_pca, y_test)
rf_smote_metrics = get_evaluation_metrics(best_rf_smote_model, X_train_smote, y_train_smote, X_test, y_test)

# DataFrame for comparison
comparison_df = pd.DataFrame({
    'Metric': list(xgb_metrics.keys()),
    'XGBoost': list(xgb_metrics.values()),
    'Random Forest': list(rf_metrics.values()),
    'XGBoost PCA': list(xgb_pca_metrics.values()),
    'Random Forest PCA': list(rf_pca_metrics.values()),
    'XGBoost SMOTE': list(xgb_smote_metrics.values()),
    'Random Forest SMOTE': list(rf_smote_metrics.values())
})

comparison_df

import seaborn as sns

# Melt the DataFrame for easier plotting
comparison_melted = comparison_df.melt(id_vars='Metric', var_name='Model', value_name='Value')

plt.figure(figsize=(12, 8))
sns.barplot(data=comparison_melted, x='Metric', y='Value', hue='Model')
plt.xticks(rotation=45, ha='right')
plt.title('Model Performance Comparison: XGBoost vs Random Forest')
plt.legend(title='Model')
plt.tight_layout()
plt.show()

"""#### Learning Curves to check for overfitting"""

from sklearn.model_selection import learning_curve

def plot_learning_curve(model, X, y, title='Learning Curve'):
    train_sizes, train_scores, test_scores = learning_curve(
        estimator=model,
        X=X,
        y=y,
        cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),
        n_jobs=-1,
        train_sizes=np.linspace(0.1, 1.0, 10),
        scoring='accuracy'
    )

    train_scores_mean = np.mean(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)

    plt.figure(figsize=(8,6))
    plt.plot(train_sizes, train_scores_mean, 'o-', color='blue', label='Training Accuracy')
    plt.plot(train_sizes, test_scores_mean, 'o-', color='red', label='Validation Accuracy')
    plt.title(title)
    plt.xlabel('Training Set Size')
    plt.ylabel('Accuracy')
    plt.legend(loc='best')
    plt.grid(True)
    plt.show()

# Plot learning curves for XGBoost and Random Forest
plot_learning_curve(best_xgb_model, X_train, y_train, title='XGBoost Learning Curve')
plot_learning_curve(best_rf_model, X_train, y_train, title='Random Forest Learning Curve')
plot_learning_curve(best_xgb_pca_model, X_train_pca, y_train, title='XGBoost PCA Learning Curve')
plot_learning_curve(best_rf_pca_model, X_train_pca, y_train, title='Random Forest PCA Learning Curve')
plot_learning_curve(best_xgb_smote_model, X_train_smote, y_train_smote, title='XGBoost SMOTE Learning Curve')
plot_learning_curve(best_rf_smote_model, X_train_smote, y_train_smote, title='Random Forest SMOTE Learning Curve')



"""### ICA - Independent Component Analysis

Part 3: Separate the provided audio file using ICA. Discuss the results and methods.
"""

from google.colab import drive
drive.mount('/content/drive')

import soundfile as sf
from sklearn.decomposition import FastICA
import numpy as np

# clean audio signal
source_1, sr1 = sf.read('/content/drive/MyDrive/Audio files for part 3/song.mp3')
source_2, sr2 = sf.read('/content/drive/MyDrive/Audio files for part 3/source_2_white_noise.wav') # Load the noisy audio signal

# Ensure both signals have the same sample rate
if sr1 != sr2:
    raise ValueError("Sample rates of the two signals must match!")

# ensure both audio signals have the same number of channels before stacking
if len(source_1.shape) == 2:
    source_1 = np.mean(source_1, axis=1)  # Average stereo channels to mono
if len(source_2.shape) == 2:
    source_2 = np.mean(source_2, axis=1)

# Align signal lengths
min_length = min(len(source_1), len(source_2))
source_1 = source_1[:min_length]
source_2 = source_2[:min_length]

# Mixing matrix (2x2)
mixing_matrix = np.array([[0.8, 0.2], [0.3, 0.7]])

# Stack the signals into a matrix (2xN)
signals = np.vstack([source_1, source_2])

# Mix the signals
mixed_signals = np.dot(mixing_matrix, signals)

# Save the mixed signals
sf.write('mixed_signal_1.wav', mixed_signals[0], sr1)
sf.write('mixed_signal_2.wav', mixed_signals[1], sr1)

# Prepare mixed signals for ICA (transpose to shape: n_samples, n_features)
mixed_signals = mixed_signals.T

# Apply ICA
ica = FastICA(n_components=2)
separated_signals = ica.fit_transform(mixed_signals)

# Save the separated components
sf.write('separated_signal_1.wav', separated_signals[:, 0], sr1)
sf.write('separated_signal_2.wav', separated_signals[:, 1], sr1)

